from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import gradio as gr
import pandas as pd
import re

df_clean=pd.read_csv('cleaned_data.csv')
# Load cleaned DataFrame with a link column
df = df_clean[['text', 'price_clean', 'location', 'facebookUrl']].copy()

# Clean numeric price column
df['price'] = pd.to_numeric(df['price_clean'], errors='coerce')

# Load MADAR-T5 (designed for Arabic dialects)
model_name = "UBC-NLP/AraT5-base"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

# Simple Darija â†’ MSA dictionary
darija_map = {
    "bghit": "Ø£Ø±ÙŠØ¯", "karhba": "Ø³ÙŠØ§Ø±Ø©", "auto": "Ø³ÙŠØ§Ø±Ø©", "voiture": "Ø³ÙŠØ§Ø±Ø©", "f": "ÙÙŠ",
    "drahem": "Ù…Ø§Ù„", "kra": "Ø¥ÙŠØ¬Ø§Ø±", "souma": "Ø³Ø¹Ø±", "ta7t": "Ø£Ù‚Ù„ Ù…Ù†", "taht": "Ø£Ù‚Ù„ Ù…Ù†",
    "ghalya": "ØºØ§Ù„ÙŠØ©", "rkhisa": "Ø±Ø®ÙŠØµØ©", "wahran": "ÙˆÙ‡Ø±Ø§Ù†", "oran": "ÙˆÙ‡Ø±Ø§Ù†", "alger": "Ø§Ù„Ø¬Ø²Ø§Ø¦Ø±",
    "dzayer": "Ø§Ù„Ø¬Ø²Ø§Ø¦Ø±", "kayn": "ÙŠÙˆØ¬Ø¯", "chouf": "Ø´Ø§Ù‡Ø¯", "dir": "Ù‚Ù…", "men": "Ù…Ù†", "fi": "ÙÙŠ",
    "3andi": "Ø¹Ù†Ø¯ÙŠ", "nheb": "Ø£Ø±ÙŠØ¯", "tsoum": "ØªÙƒÙ„ÙØ©", "chwiya": "Ù‚Ù„ÙŠÙ„", "bzaaf": "ÙƒØ«ÙŠØ±",
    "mlih": "Ø¬ÙŠØ¯", "marque": "Ù…Ø§Ø±ÙƒØ©", "modele": "Ù…ÙˆØ¯ÙŠÙ„", "nif": "Ø¬Ø¯ÙŠØ¯Ø©", "qdima": "Ù‚Ø¯ÙŠÙ…Ø©"
}

def translate_darija_to_standard(text):
    words = text.lower().split()
    translated = [darija_map.get(word.strip(), word) for word in words]
    return " ".join(translated)

# Filter dataset based on simple rule-based logic
def search_cars(query):
    df_filtered = df.copy()

    # City filters
    if "ÙˆÙ‡Ø±Ø§Ù†" in query:
        df_filtered = df_filtered[df_filtered['location'].str.contains("ÙˆÙ‡Ø±Ø§Ù†", na=False)]
    if "Ø§Ù„Ø¬Ø²Ø§Ø¦Ø±" in query:
        df_filtered = df_filtered[df_filtered['location'].str.contains("Ø§Ù„Ø¬Ø²Ø§Ø¦Ø±", na=False)]

    # Price filtering
    match = re.search(r"Ø£Ù‚Ù„ Ù…Ù† (\d+)", query)
    if match:
        try:
            price_limit = int(match.group(1)) * 1000  # adjust as needed
            df_filtered = df_filtered[df_filtered['price'] < price_limit]
        except:
            pass

    return df_filtered.head(3).to_dict("records")

# Generate chatbot response
def generate_response(user_input):
    std_query = translate_darija_to_standard(user_input)

    # Optionally generate full prompt with MADAR-T5
    inputs = tokenizer.encode(std_query, return_tensors="pt", max_length=128, truncation=True)
    _ = model.generate(inputs)  # just to simulate transformer usage, for now not used in filtering

    results = search_cars(std_query)

    if len(results) > 0:
        response = f"ğŸš— Kayn {len(results)} 3roud li ykhdmouk:\n\n"
        for i, car in enumerate(results, 1):
            title = car['text']
            price = int(car['price'])
            city = car['location']
            link = car['facebookUrl']
            response += f"{i}. ğŸš™ {title}\n   ğŸ’° {price:,} \n   ğŸ“ {city}\n   ğŸ”— [Voir annonce]({link})\n\n"
        response += "ğŸ“© T7eb nwarik kter?"
    else:
        response = "ğŸ«¤ Ma l9it walou f had condition... JØ±Ø¨ Ø¨ÙƒÙ„Ù…Ø§Øª Ø®Ø±Ø§ wala souma okhra."

    return response

# Launch Gradio UI
gr.Interface(
    fn=generate_response,
    inputs="text",
    outputs="text",
    title="ğŸš— Chatbot Dziria - Car Market DZ",
    description="Sa9si 3la sayarat b darija, ou chatbot ywarik l3roud ğŸ“Š",
    theme="default"
).launch()
